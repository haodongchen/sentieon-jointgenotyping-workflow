{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9c02645-f73e-4041-a63b-8970757e41d2",
   "metadata": {},
   "source": [
    "# Joint Cohort Calling\n",
    "For power users of CAVATICA with cohorts larger than 2,200, but also one in which any instance being used will not exceed 4TB in EBS storage\n",
    "1. Set up CAVATICA credentials\n",
    "1. Set up split Split by chr jobs and run\n",
    "1. Tag split jobs so that they can be easily found and deleted later\n",
    "1. Run Genotyper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d5d0ca-a9be-4f15-8b97-f8dc8c05119a",
   "metadata": {},
   "source": [
    "## Set up imports and creds\n",
    "Credential set up using developer token allows you to set up task jobs. By design, token is deleted after creds file is created. Creds file should disappear after session which is secure. If you're running locally, adjust accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ff4a5c-d5e9-4dd3-bd54-e01cd9cfb59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import sevenbridges as sbg\n",
    "from sevenbridges.errors import SbgError\n",
    "from sevenbridges.http.error_handlers import rate_limit_sleeper, maintenance_sleeper\n",
    "from getpass import getpass\n",
    "import pdb\n",
    "\n",
    "config_name =  \"/home/jovyan/.sevenbridges/credentials\"\n",
    "try:\n",
    "    os.mkdir(\"/home/jovyan/.sevenbridges\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "config_file=open(config_name, 'w')\n",
    "\n",
    "endpoint='api_endpoint = https://cavatica-api.sbgenomics.com/v2\\n'\n",
    "token = getpass('Enter your sbg token:')\n",
    "config_file.write(\"[default]\\n\" + endpoint + \"auth_token = \" + token)\n",
    "config_file.close()\n",
    "config = sbg.Config(profile='default')\n",
    "api = sbg.Api(config=config, error_handlers=[rate_limit_sleeper, maintenance_sleeper])\n",
    "del token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ec69a4-8714-47f6-9cf5-7348f798f617",
   "metadata": {},
   "source": [
    "## Set up split jobs\n",
    "Need to have created a list of chromosomes to use for splitting and downstream joint calling. Recommend chr1-22,X,Y,M. **Also recommend at project level to turn on Spot Instances and Memoization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cb12c7-12c1-4dd7-8d47-6c0fc9afab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'd3b-bixu/kf-chd-all-joint-call-temp'\n",
    "chr_list = 'split_vcf_chr_list.txt'\n",
    "chr_obj = api.files.query(project=project, names=[chr_list])[0]\n",
    "chr_array = chr_obj.content().rstrip('\\n').split(\"\\n\")\n",
    "split_by_chr = True\n",
    "gvcf_files = api.files.query(project=project, tags=[\"PORTAL\"]).all()\n",
    "\n",
    "gvcf_set_list = []\n",
    "gvcf_set_list.append([])\n",
    "j=0\n",
    "x = 1\n",
    "n = 39 # set so that 60 tasks are made\n",
    "# create set tasks - n per set\n",
    "for gvcf in gvcf_files:\n",
    "    if x > n:\n",
    "        gvcf_set_list.append([])\n",
    "        j += 1\n",
    "        x=1\n",
    "        print('Creating next set of ' + str(n), file=sys.stderr)\n",
    "    gvcf_set_list[j].append(gvcf)\n",
    "    x += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52074d40-6fd8-4e7f-9f5b-92d745464f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = 1\n",
    "# Tinker with this based on expected input size a level of desired stacking\n",
    "instance_type: \"c5.12xlarge;ebs-gp2;1500\"\n",
    "app_name = project + \"/split-vcf-mini-workflow\"\n",
    "for gvcf_set in gvcf_set_list:\n",
    "    in_dict = {\"chr_list\": chr_obj, \"chr_array\": chr_array, \"input_vcf\": gvcf_set}\n",
    "    task_name = \"Split VCF by chr set: \" + str(ct)\n",
    "    task = api.tasks.create(app=app_name, name=task_name, inputs=in_dict, project=project, run=False, execution_settings = {\"instance_type\": [instance_type]})\n",
    "    task.save()\n",
    "    ct +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525b5898-d300-49e9-9e16-837e314e3f83",
   "metadata": {},
   "source": [
    "### Run the split tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e218ee65-6b63-465d-847e-f79c718d3df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = api.tasks.query(project=project, status=\"DRAFT\").all()\n",
    "phrase = \"Split VCF by chr set\"\n",
    "for task in tasks:\n",
    "    if task.name.startswith(phrase):\n",
    "        task.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c274cbe-addd-4863-b2d1-b43ded564ddc",
   "metadata": {},
   "source": [
    "## Tag outputs\n",
    "Useful to organize inputs. Uses bulk get and bulk update - absolutely critical as per-file get and save will cause you to hit the api limit even if you have a turbo token real fast!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5525e63-f46b-4b04-9c6c-aad963664a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'd3b-bixu/kf-chd-all-joint-call-temp'\n",
    "chr_list = 'split_vcf_chr_list.txt'\n",
    "chr_obj = api.files.query(project=project, names=[chr_list])[0]\n",
    "chr_array = chr_obj.content().rstrip('\\n').split(\"\\n\")\n",
    "\n",
    "tasks = api.tasks.query(project=project, status=\"COMPLETED\").all()\n",
    "phrase = \"Split VCF by chr set\"\n",
    "for task in tasks:\n",
    "    if task.name.startswith(phrase):\n",
    "        print(task.name)\n",
    "        for outdir in task.outputs['split_vcfs']:\n",
    "            split_set = api.files.bulk_get(outdir)\n",
    "            update_set = []\n",
    "            for bulk_file in split_set:\n",
    "                try:\n",
    "                    # update vcfs\n",
    "                    parts = bulk_file.resource.name.split(\"_\")\n",
    "                    bulk_file.resource.tags.extend([parts[0], \"INTERMEDIATE\"])\n",
    "                    update_set.append(bulk_file.resource)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(\"{} {}\".format(e, \"\\nFailed in VCF loop\"))\n",
    "                    pdb.set_trace()\n",
    "                    hold = 1\n",
    "            # update secondary files, just the intermediate tag to make it easy to find to delete\n",
    "            secondary = [x.secondary_files[0] for x in outdir]\n",
    "            bulk_index = api.files.bulk_get(secondary)\n",
    "            for index_file in bulk_index:\n",
    "                try:\n",
    "                    # update indexes\n",
    "                    index_file.resource.tags.append(\"INTERMEDIATE\")\n",
    "                    update_set.append(index_file.resource)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(\"{} {}\".format(e, \"\\nFailed in index loop\"))\n",
    "                    pdb.set_trace()\n",
    "                    hold = 1\n",
    "            try:\n",
    "                api.files.bulk_update(update_set)\n",
    "            except Exception as e:\n",
    "                print(\"{} {}\".format(e, \"\\nFailed in update\"))\n",
    "                pdb.set_trace()\n",
    "                hold=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba26833-6018-471c-a847-52ef97cb2652",
   "metadata": {},
   "source": [
    "## Set up joint call tasks\n",
    "Adjust the variables at the start as-needed to fit your project/preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adaa550-4973-459e-8295-448c5de4b59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up some static inputs here\n",
    "cpus = 48\n",
    "# split by chr is beefy - maxing out disk space to be safe\n",
    "instance_type = \"c5.12xlarge;ebs-gp2;4000\"\n",
    "reference_name = \"Homo_sapiens_assembly38.fasta\"\n",
    "dbsnp_name = \"Homo_sapiens_assembly38.dbsnp.vcf.gz\"\n",
    "sentieon_license=\"10.5.64.221:8990\"\n",
    "out_file_prefix = \"KF-CHDALL_\"\n",
    "ref_dict={ \"reference\": api.files.query(project=project, names=[reference_name])[0], \"dbSNP\": api.files.query(project=project, names=[dbsnp_name])[0], \"sentieon_license\": sentieon_license, \"cpu_per_job\": cpus }\n",
    "app_name = project + \"/sentieon-gvcftyper\"\n",
    "\n",
    "for chrom in chr_array:\n",
    "    task_name = \"Sentieon GVCFtyper: \" + chrom\n",
    "    # convert collection object to list of objects, then sort to ensure each job has the samples in the same order\n",
    "    input_gvcf_collection = api.files.query(project=project, tags=[chrom]).all()\n",
    "    # list conversion might take 10 seconds or so\n",
    "    input_gvcf_list = list(input_gvcf_collection)\n",
    "    input_gvcf_list.sort(key=lambda x: x.name)\n",
    "    in_dict = {}\n",
    "    for key in ref_dict:\n",
    "        in_dict[key] = ref_dict[key]\n",
    "    in_dict['input_gvcf_files'] = input_gvcf_list\n",
    "    in_dict['interval'] = chrom\n",
    "    in_dict['output_file_name'] = out_file_prefix + chrom + \".vcf.gz\"\n",
    "    task = api.tasks.create(app=app_name, name=task_name, inputs=in_dict, project=project, run=False, execution_settings = {\"instance_type\": [instance_type]} )\n",
    "    print(\"Created \" + task.name)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f72b46-2c7a-475b-beba-9f217fe9089d",
   "metadata": {},
   "source": [
    "### Run the GT Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b20c0e-fe46-487b-97e2-429c0d303827",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = api.tasks.query(project=project, status=\"DRAFT\").all()\n",
    "phrase = \"Sentieon GVCFtyper\"\n",
    "for task in tasks:\n",
    "    if task.name.startswith(phrase):\n",
    "        task.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53943e81-797d-4ad9-89e3-8b955dc9f3c7",
   "metadata": {},
   "source": [
    "## MISC\n",
    "Not needed but might be useful to get some cost and run time info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e588784-e3e2-441f-ad10-0caa94952327",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'd3b-bixu/kf-chd-all-joint-call-temp'\n",
    "tasks = api.tasks.query(project=project).all()\n",
    "phrase = \"Split VCF by chr set\"\n",
    "gt_phrase = \"Sentieon GVCFtyper:\"\n",
    "split_total = 0\n",
    "gt_total = 0\n",
    "gt_run_time = {}\n",
    "split_run_time = {}\n",
    "total_total = 0\n",
    "for task in tasks:\n",
    "    if task.price is not None:\n",
    "        run_hours=(task.end_time - task.start_time).seconds/3600\n",
    "        total_total += task.price.amount\n",
    "        if task.name.startswith(phrase):\n",
    "            split_total += task.price.amount\n",
    "            if task.name not in split_run_time:\n",
    "                split_run_time[task.name] = run_hours\n",
    "            else:\n",
    "                split_run_time[task.name] += run_hours\n",
    "        elif task.name.startswith(gt_phrase):\n",
    "            gt_total += task.price.amount\n",
    "            if task.name not in split_run_time:\n",
    "                gt_run_time[task.name] = run_hours\n",
    "            else:\n",
    "                gt_run_time[task.name] += run_hours\n",
    "\n",
    "print(\"Total spent so far: {}, Split costs: {}, GT costs {}\".format(total_total, split_total, gt_total))\n",
    "with open(\"split_run_times.txt\", 'w') as s:\n",
    "    for task_name in split_run_time:\n",
    "        print(\"{}\\t{}\".format(task_name, split_run_time[task_name]), file=s)\n",
    "with open(\"gt_run_times.txt\", 'w') as f:\n",
    "    for task_name in gt_run_time:\n",
    "        print(\"{}\\t{}\".format(task_name, gt_run_time[task_name]), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd076fff-071e-4119-84cc-5d889fcdda77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
